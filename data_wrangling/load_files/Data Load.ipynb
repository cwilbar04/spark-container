{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96edfad5-0725-4db1-9bf3-a0ea6844961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, BooleanType, ArrayType, LongType\n",
    "import pyspark.sql.functions as f\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd3a7f-3b98-455f-8eed-86ede7ac998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GCS bucket name\n",
    "gcs_bucket = f'amazon_reviews_bucket'\n",
    "gcs_filepath = f'gs://{gcs_bucket}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c27394-d5a9-429e-9899-ed3267f72d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session and Load BigQuery jar file\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Load Review Files\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/spark-bigquery-with-dependencies_2.12-0.20.0.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258d78f-4fa3-4ac8-8b2d-4132531d0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema of files to parse\n",
    "# Auto-parse fails due to duplicate keys in the style Array\n",
    "# Need to parse in as array\n",
    "schema = StructType([ \n",
    "    StructField(\"asin\",StringType(),True), \n",
    "    StructField(\"image\",ArrayType(StringType()),True), \n",
    "    StructField(\"overall\",DoubleType(),True),\n",
    "    StructField(\"reviewText\",StringType(),True),\n",
    "    StructField(\"reviewTime\",StringType(),True),\n",
    "    StructField(\"reviewerID\",StringType(),True),\n",
    "    StructField(\"reviewerName\",StringType(),True),\n",
    "    StructField(\"summary\",StringType(),True),\n",
    "    StructField(\"unixReviewTime\",LongType(),True),\n",
    "    StructField(\"verified\",BooleanType(),True),\n",
    "    StructField(\"vote\",StringType(),True),\n",
    "    StructField(\"style\",ArrayType(StringType()),True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504db3e2-5707-4b27-a88d-97d4efc92abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to scrape to get files to download\n",
    "url = \"https://nijianmo.github.io/amazon/index.html\"\n",
    "html = requests.get(url)\n",
    "\n",
    "# Get HTML from website\n",
    "if html.ok:\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')  \n",
    "\n",
    "# Parse website for '5-core' links and add the file to the SparkContext for later download\n",
    "# Store list of file names \n",
    "output_final = []\n",
    "files = []\n",
    "links = soup.find_all('a',string='5-core')#.find('5-core')#.find_all('td', id='5-core')\n",
    "for link in links:\n",
    "    url = link.get('href')\n",
    "    file = url.split('/')[-1]\n",
    "    print(url)\n",
    "    print(url.split('/')[-1])\n",
    "    spark.sparkContext.addFile(url)\n",
    "    files.append(file)\n",
    "\n",
    "# Loop through each file, delete duplicates based on multiple product ID's for the same product, differnt color\n",
    "# Calculate word count of review\n",
    "# Create standard fields and load in to GCP Bucket\n",
    "loaded = []\n",
    "for file in files:    \n",
    "    df = spark.read.json(\"file://\"+SparkFiles.get(file),schema)\n",
    "    df = df.dropDuplicates(['reviewerID','overall','summary','reviewText']) \n",
    "    df = df.withColumn('review_wordCount', f.size(f.split(f.col('reviewText'), ' ')))\n",
    "    df.registerTempTable(\"dataframe\")\n",
    "    sql_script = f\"\"\"select \n",
    "              '{file.split('.')[0]}' as category,\n",
    "              asin || '-' || reviewerID || '-' || row_number() OVER (PARTITION BY reviewerID ORDER BY unixReviewTime asc) as review_ID,\n",
    "              asin as product_ID,\n",
    "              reviewerID as reviewer_ID,\n",
    "              overall as rating_out_of_5,\n",
    "              summary as review_summary,\n",
    "              reviewText as review_text,\n",
    "              review_wordCount as review_word_count,  \n",
    "              verified,\n",
    "              vote,\n",
    "              reviewTime,\n",
    "              unixReviewTime,\n",
    "              image,\n",
    "              '{url}' as source_url\n",
    "            from dataframe\"\"\"\n",
    "    output = spark.sql(sql_script)\n",
    "    print(f'Data load started for {file}')\n",
    "    output.write \\\n",
    "      .format(\"bigquery\") \\\n",
    "      .option(\"temporaryGcsBucket\",gcs_bucket) \\\n",
    "      .mode(\"append\") \\\n",
    "      .save(\"amazon_reviews.categoryFilesSmall\")\n",
    "    output.unpersist()\n",
    "    print(f'Data loaded to Bigquery for {file}')\n",
    "    loaded.append(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
