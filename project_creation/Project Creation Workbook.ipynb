{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compact-currency",
   "metadata": {},
   "source": [
    "# Google Cloud Platform Project Creation Workbook \n",
    " \n",
    "Use this workbook to create a google cloud project with everything needed to collect new data and host your own web app. \n",
    " \n",
    "Prerequisites:  \n",
    "+ Create Google user account  <br><br>\n",
    "+ Create your own personal Google Cloud Project and Enable Billing\n",
    "    - Enable Free Tier account by seleting \"Try it Free\" here: [Try Google Cloud Platform for free](https://cloud.google.com/cloud-console)\n",
    "    - Follow steps to activate billing found here: [Create New Billing Account](https://cloud.google.com/billing/docs/how-to/manage-billing-account#create_a_new_billing_account)\n",
    "        - Billing account is required for APIs used in this project\n",
    "        - You will not exceed the $300 free trial setting up this project but make sure to delete the project if you do not want to be charged\n",
    "        - Take note of project name created because this billing account will be used with the new project <br><br>\n",
    "+ Install and initialize Google Cloud SDK by following instructions found here: [Cloud SDK Quickstart](https://cloud.google.com/sdk/docs/quickstart) <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-kansas",
   "metadata": {},
   "source": [
    "## Step 1 - Check Prequisites Successfully Completed\n",
    "Check that you have successfully installed and enabled Cloud SDK by running the config list command. If you get an error please refer to Troubleshooting steps found here [Cloud SDK Quickstart](https://cloud.google.com/sdk/docs/quickstart).  \n",
    "You should see an output that includes your account along with any other configuration setup when using gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud config list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-cooperation",
   "metadata": {},
   "source": [
    "## Step 2 - Create GCP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TO DO: Enter name for new project\n",
    "###### Note: Proect name must be unique across GCP. If you get error when creating project please change the project name here and try again.\n",
    "\n",
    "new_project_id = 'nba-predictions-demo-3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud projects create {new_project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-teacher",
   "metadata": {},
   "source": [
    "#### IMPORTANT\n",
    "*****TO DO: Navigate to [Cloud Console](https://console.cloud.google.com/), Change to new project, and enable billing following instructions found here: [Enable Billing](https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project)***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-prediction",
   "metadata": {},
   "source": [
    "## Step 3 - Enable Necessary Cloud Services\n",
    "\n",
    "This project uses:\n",
    "+ BigQuery to Store Model Data \n",
    "+ Google Cloud Functions scheduled using Google Cloud Scheduler to Load new Data Daily\n",
    "+ Google App Engine to Host Website\n",
    "+ Google Firestore in Native Mode to store data used by the Web Page  \n",
    "  \n",
    "List below contains all services needed at time of creation of this workbook. Please add/remove from this list if the names/necessary services have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_services_list = [\n",
    "    'appengine.googleapis.com',\n",
    "    'bigquery.googleapis.com',\n",
    "    'bigquerystorage.googleapis.com',\n",
    "    'cloudapis.googleapis.com',\n",
    "    'cloudbuild.googleapis.com',\n",
    "    'clouddebugger.googleapis.com',\n",
    "    'cloudfunctions.googleapis.com',\n",
    "    'cloudresourcemanager.googleapis.com',\n",
    "    'cloudscheduler.googleapis.com',\n",
    "    'cloudtrace.googleapis.com',\n",
    "    'compute.googleapis.com',\n",
    "    'datastudio.googleapis.com',\n",
    "    'deploymentmanager.googleapis.com',\n",
    "    'firebaserules.googleapis.com',\n",
    "    'firestore.googleapis.com',\n",
    "    'logging.googleapis.com',\n",
    "    'monitoring.googleapis.com',\n",
    "    'oslogin.googleapis.com',\n",
    "    'servicemanagement.googleapis.com',\n",
    "    'serviceusage.googleapis.com',\n",
    "    'sql-component.googleapis.com',\n",
    "    'storage-api.googleapis.com',\n",
    "    'storage-component.googleapis.com',\n",
    "    'storage.googleapis.com'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Services can only be enabled 20 at a time at the time of workbook creation. Use this loop to enable 20 at a time.\n",
    "for x in range(0,len(enable_services_list),20):\n",
    "    !gcloud services enable {' '.join(enable_services_list[x:(x+20)])} --project={new_project_id}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that services were enabled\n",
    "!gcloud services list --project={new_project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-recipient",
   "metadata": {},
   "source": [
    "## Step 4 - Create Necessary Service Accounts\n",
    "\n",
    "There are four primary service accounts used in this project:  \n",
    "- **App Engine default service account**\n",
    "    - This gets created automatically when the App engine API is enabled\n",
    "    - Generally your_project_id@appspot.gserviceaccount.com  <br><br>\n",
    "      \n",
    "- **Compute Engine default service account**\n",
    "    - This gets created automatically when the Compute engine API is enabled\n",
    "    - Generally your_project_number-compute@developer.gserviceaccount.com  <br><br>\n",
    "      \n",
    "- **Cloud Function service account**\n",
    "    - We create this and add necessary roles below using the Cloud SDK\n",
    "    - cloudfunction-service-account@your_project_name.iam.gserviceaccount.com\n",
    "    - This account is used as the service account to run all Cloud Functions in this project  <br><br>\n",
    "      \n",
    "- **CircleCI Service Account**\n",
    "    - We create this and add necessary roles below using the Cloud SDK\n",
    "    - circleci-deployer@your_project_name.iam.gserviceaccount.com\n",
    "    - This account is used in CircleCI for CI\\CD to deploy and test App Engine and Cloud Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-climate",
   "metadata": {},
   "source": [
    "Check what service ccounts are already created (should be the two default ones described above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud iam service-accounts list --project={new_project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud iam service-accounts create cloudfunction-service-account \\\n",
    "    --display-name=\"Cloud Function Service Account\" \\\n",
    "    --description=\"Account used to run all Cloud Functions with necessary BigQuery and Firestore Permissions\" \\\n",
    "    --project={new_project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud iam service-accounts create circleci-deployer \\\n",
    "    --display-name=\"Circle CI Service Account\" \\\n",
    "    --description=\"Account used by Circle CI with necessary permissions to Deploy to Cloud Functions and App Engine\" \\\n",
    "    --project={new_project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-junior",
   "metadata": {},
   "source": [
    "Check service accounts were created successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud iam service-accounts list --project={new_project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-collect",
   "metadata": {},
   "source": [
    "Programatically update the roles for the new service accounts using the guide found here: [Programatic Change Access](https://cloud.google.com/iam/docs/granting-changing-revoking-access#programmatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save policy file in directory above where the repo is saved so that it is not stored to github\n",
    "file_directory = '..\\..\\policy.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write current policy to file directory\n",
    "!gcloud projects get-iam-policy {new_project_id} --format json > {file_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-bundle",
   "metadata": {},
   "source": [
    "**If running jupyter notebook run below cell to load and modify policy file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('..\\..\\policy.json') as f:\n",
    "    policy = json.load(f)\n",
    "\n",
    "def modify_policy_add_role(policy, role, member):\n",
    "    \"\"\"Adds a new role binding to a policy.\"\"\"\n",
    "\n",
    "    binding = {\"members\": [member],\"role\": role }\n",
    "    policy[\"bindings\"].append(binding)\n",
    "    return policy\n",
    "\n",
    "members = [f'serviceAccount:cloudfunction-service-account@{new_project_id}.iam.gserviceaccount.com', \n",
    "           f'serviceAccount:circleci-deployer@{new_project_id}.iam.gserviceaccount.com']\n",
    "roles = {members[0]:['roles/bigquery.dataEditor','roles/datastore.user','roles/run.serviceAgent', 'roles/bigquery.user',\n",
    "                    'roles/storage.admin'],\n",
    "        members[1]:['roles/appengine.deployer','roles/appengine.serviceAdmin','roles/cloudbuild.builds.builder',\n",
    "                   'roles/cloudfunctions.admin','roles/compute.storageAdmin','roles/iam.serviceAccountUser']}\n",
    "\n",
    "for member in members:\n",
    "    for role in roles[member]:\n",
    "        policy = modify_policy_add_role(policy, role, member)\n",
    "\n",
    "with open('..\\..\\policy.json', 'w') as json_file:\n",
    "    json.dump(policy, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-sentence",
   "metadata": {},
   "source": [
    "**If running code direct in console, navigate to file path and add the members and roles below in to the file path**  \n",
    "**Change \"your_project_id\" to the name of your project id**\n",
    "\n",
    "{\"members\": [\"serviceAccount:cloudfunction-service-account@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/bigquery.user\"},  \n",
    "{\"members\": [\"serviceAccount:cloudfunction-service-account@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/datastore.user\"},  \n",
    "{\"members\": [\"serviceAccount:cloudfunction-service-account@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/run.serviceAgent\"},  \n",
    "{\"members\": [\"serviceAccount:circleci-deployer@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/appengine.deployer\"},   \n",
    "{\"members\": [\"serviceAccount:circleci-deployer@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/appengine.serviceAdmin\"},   \n",
    "{\"members\": [\"serviceAccount:circleci-deployer@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/cloudbuild.builds.builder\"},   \n",
    "{\"members\": [\"serviceAccount:circleci-deployer@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/cloudfunctions.admin\"},  \n",
    "{\"members\": [\"serviceAccount:circleci-deployer@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/compute.storageAdmin\"},  \n",
    "{\"members\": [\"serviceAccount:circleci-deployer@your_project_id.iam.gserviceaccount.com\"], \"role\": \"roles/iam.serviceAccountUser\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud projects set-iam-policy {new_project_id} {file_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove policy file \n",
    "!del {file_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-hierarchy",
   "metadata": {},
   "source": [
    "## Step 5 - Create App Engine Application & Firestore in Native Mode Database\n",
    "\n",
    "In order to deploy a specific application you first need to create a placeholder application.\n",
    "\n",
    "This application will get the latest infomration for each team from storage in Firestore in Native Mode. We create an empty database here to change the Firestore mode from Datastore Mode to Native Mode.\n",
    "\n",
    "**Change YOUR_REGION to your default region**  \n",
    "See [Regions and Zone](https://cloud.google.com/compute/docs/regions-zones) for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO: Change region to your default region\n",
    "region = 'us-central'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud app create --region={region} --project={new_project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud firestore databases create --region={region} --project={new_project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-inspection",
   "metadata": {},
   "source": [
    "## Step 6 - Create BigQuery Dataset\n",
    "\n",
    "Your new project will need a dataset to store the data if you plan on copying/creating your own repository of data.  \n",
    "\n",
    "This has to be a unique name per project.  \n",
    "\n",
    "In my workflows I have named the dataset 'nba' but feel free to change it. Note that if you do change it, then you will also need to change the dataset name in any of the other python scripts in this project appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'nba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop and re-run if this takes more than a minute\n",
    "!bq --location=US mk --dataset \\\n",
    "--description \"Stores all National Basketball Association Data. Created using Project Creation workbook found at https://github.com/cwilbar04/nba-predictions/tree/main/notebooks\" \\\n",
    "{new_project_id}:{dataset_name}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-missouri",
   "metadata": {},
   "source": [
    "## Step 7 - Load BigQuery Tables\n",
    "\n",
    "All data in this project is taken from [BASEKTBALL REFERENCE](https://www.basketball-reference.com/)\n",
    "\n",
    "There are two options for loading the data to BigQuery:  \n",
    "1. **Load the data yourself** \n",
    "    - Part 1: Raw Data\n",
    "        - Navigate to [Initial Load Workbook](https://github.com/cwilbar04/nba-predictions/blob/main/notebooks/NBA%20Data%20Initial%20Load.ipynb) and change start date to desired starting date. For my model I loaded data starting from '10-1-1999'. Always choose a start date in between seasons if you don't want to get partial season data. Warning this may take a couple days and require re-starts. \n",
    "    - Part 2: Model Data\n",
    "        - Navigate to [Initial Model Load Workbook](https://github.com/cwilbar04/nba-predictions/blob/main/notebooks/NBA%20Model%20Table%20Initial%20Load.ipynb) and change project and dataset names to what you used in the workbook then run all. <br><br>\n",
    "2. **Copy Data**\n",
    "    - For a quicker load process, simply copy the data directly from my public data set by running the code blocks below. You must completed Step 6 - Create BigQuery Dataset first. Be careful of costs if dataset you create is in a different region than US. At time of creation this is still in beta and there is no cost. See documentation here for latest info: [Copy Datasets](https://cloud.google.com/bigquery/docs/copying-datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Copy Dataset Code Block. Only run if choosing option 2 above ####\n",
    "## You first have to enable Data Transfer Service API ##\n",
    "!gcloud services enable bigquerydatatransfer.googleapis.com --project={new_project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Copy Dataset Code Block. Only run if choosing option 2 above ####\n",
    "## Enabling the Data Transfer Service API can take a minute. Please wait and retry if you get an error\"   ##\n",
    "## Below code must be run in python. To run outside of python please replace {} with correct information. ##\n",
    "## Params must be JSON formatted                                                                          ##\n",
    "## Data will be transfered from my public data set to the dataset you created in Step 6 above ##\n",
    "\n",
    "import json\n",
    "source_parameters = '{\"source_dataset_id\":\"nba\", \"source_project_id\":\"nba-predictions-prod\", \"overwrite_destination_table\":\"true\"}'\n",
    "source_parameters_json = json.dumps(source_parameters)\n",
    "run = f'bq mk --transfer_config\\\n",
    "                --project_id={new_project_id}\\\n",
    "                --data_source=cross_region_copy\\\n",
    "                --target_dataset={dataset_name}\\\n",
    "                --display_name=\"Initial load of public NBA dataset\"\\\n",
    "                --params={source_parameters_json}'\n",
    "!{run}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO! Replace the bottom line with the text in quotes from the successful setup step above (the resource name)\n",
    "## Must delete the transfer config after creation so that it only runs once\n",
    "## Any job in progress will complete prior to deletion\n",
    "!bq rm \\\n",
    "-f \\\n",
    "--transfer_config \\\n",
    "projects/357163051572/locations/us/transferConfigs/60b55a37-0000-2bc3-acd5-240588740f2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you accidentally re-ran the create step, run this to get a list of Transfer services and delete them all\n",
    "## Also run to check that it was actually deleted.\n",
    "!bq ls \\\n",
    "--transfer_config \\\n",
    "--transfer_location=US\\\n",
    "--project_id={new_project_id}\\\n",
    "--filter=dataSourceIds:cross_region_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-sheep",
   "metadata": {},
   "source": [
    "## Step 8 - Deploy Cloud Functions\n",
    "\n",
    "This project uses three cloud functions that we will set up schedules for using Cloud Scheduler in order to update the data daily:\n",
    "1. **nba_basketball_reference_scraper**\n",
    "    - This funciton allows you to specify a start date and end date in a JSON header ({\"StartDate\":\"1-1-1000\",\"EndDate\":\"1-1-100\"}) for game box scores and game player box scores from [BASEKTBALL REFERENCE](https://www.basketball-reference.com/) to nba.raw_basketballreference_game and nba.raw_basketballreference_playerbox.\n",
    "    - If you don't provide a start date then it automatically uses the max game date from the raw_basketballreference_game table.\n",
    "    - If you don't specify an end date then it automatically loads data up to yesterday (aka the last day games were guaranteed to be completed).\n",
    "    - When we schedule this job we will not provide a start date or end date so it will always load the most recent data that is not already in the raw_basketballreference_game and raw_basketballreference_playerbox tables. <br><br>\n",
    "       \n",
    "2. **nba_model_game_refresh**\n",
    "    - This function uses the view we will create in the next step to identify games that have been loaded to the raw_basketballreference_game table but have not been loaded in to the model_game_data table yet. It then performs all of the necessary transformations to combine specific player data stats and create moving average columns and load the data in to the model_game_data table.\n",
    "    - This job also loads the most recent information for each team to Firestore that our web app uses when making predictions.\n",
    "    - This job does not care what is in the JSON header.\n",
    "    - We will schedule this to run daily one hour after the scraper function. <br><br>\n",
    "    \n",
    "3. **nba_get_upcoming_games**\n",
    "    - This function gets the schedule from [BASEKTBALL REFERENCE](https://www.basketball-reference.com/) for one week, including \"today\" and overwrites the schedule file stored in the App Engine default cloud storage bucket. This schedule will be used to display upcoming games on our web page.\n",
    "    - This function will be scheduled to run one hour before the scraper function.\n",
    "  \n",
    "**NOTE:** All three functions are set to be allow all users to invoke them in the current build. This is to avoid setting up credentialing for cloud scheduler. Future build will seek to remove this vulnerability by properly setting up Cloud Scheduler credentials.\n",
    "\n",
    "**IMPORTANT** The deploy functions will only run if you have launched this notebook from a git cloned folder. Otherwise, you will need to change the \"source\" to the file path where the folders containing the relevant functions and requirements exist.\n",
    "\n",
    "**NOTE:** Deploying can take some time, up to 5 minutes, for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set variables used in each deploy. You should not need to change these if you have followed \n",
    "# all of the steps about in creating the service account and creating the app engine.\n",
    "CLOUD_FUNCTION_SERVICE_ACCOUNT = f'cloudfunction-service-account@{new_project_id}.iam.gserviceaccount.com'\n",
    "CLOUD_STORAGE_BUCKET = f'{new_project_id}.appspot.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy function\n",
    "FUNCTION_NAME='nba_basketball_reference_scraper'\n",
    "\n",
    "!gcloud functions deploy {FUNCTION_NAME} \\\n",
    "  --source=../scraper \\\n",
    "  --project={new_project_id} \\\n",
    "  --allow-unauthenticated \\\n",
    "  --entry-point=nba_basketballreference_scraper \\\n",
    "  --memory=1024MB \\\n",
    "  --runtime=python38 \\\n",
    "  --service-account={CLOUD_FUNCTION_SERVICE_ACCOUNT} \\\n",
    "  --trigger-http \\\n",
    "  --timeout=300\n",
    "\n",
    "# Set policy on function to allow allUsers to invoke\n",
    "!gcloud functions add-iam-policy-binding {FUNCTION_NAME} \\\n",
    "  --member=allUsers \\\n",
    "  --role=roles/cloudfunctions.invoker \\\n",
    "  --project={new_project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy function\n",
    "FUNCTION_NAME='nba_model_game_refresh'\n",
    "\n",
    "!gcloud functions deploy {FUNCTION_NAME} \\\n",
    "  --source=../data_model \\\n",
    "  --project={new_project_id} \\\n",
    "  --allow-unauthenticated \\\n",
    "  --entry-point=create_model_data \\\n",
    "  --memory=1024MB \\\n",
    "  --runtime=python38 \\\n",
    "  --service-account={CLOUD_FUNCTION_SERVICE_ACCOUNT} \\\n",
    "  --trigger-http \\\n",
    "  --timeout=300\n",
    "\n",
    "# Set policy on function to allow allUsers to invoke\n",
    "!gcloud functions add-iam-policy-binding {FUNCTION_NAME} \\\n",
    "  --member=allUsers \\\n",
    "  --role=roles/cloudfunctions.invoker \\\n",
    "  --project={new_project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy function\n",
    "FUNCTION_NAME='nba_get_upcoming_games'\n",
    "\n",
    "!gcloud functions deploy {FUNCTION_NAME} \\\n",
    "  --source=../get_schedule \\\n",
    "  --project={new_project_id} \\\n",
    "  --allow-unauthenticated \\\n",
    "  --entry-point=write_to_bucket \\\n",
    "  --memory=512MB \\\n",
    "  --runtime=python38 \\\n",
    "  --service-account={CLOUD_FUNCTION_SERVICE_ACCOUNT} \\\n",
    "  --trigger-http \\\n",
    "  --timeout=60 \\\n",
    "  --set-env-vars=CLOUD_STORAGE_BUCKET={CLOUD_STORAGE_BUCKET}\n",
    "\n",
    "# Set policy on function to allow allUsers to invoke\n",
    "!gcloud functions add-iam-policy-binding {FUNCTION_NAME} \\\n",
    "  --member=allUsers \\\n",
    "  --role=roles/cloudfunctions.invoker \\\n",
    "  --project={new_project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-chest",
   "metadata": {},
   "source": [
    "## Step 9 - Create BigQuery View\n",
    "\n",
    "In order to use the nba_model_game_refresh function we need to create a Big Query view that identifies what games have been loaded in to the raw_basektballrefernce_game table but have not been loaded in to the model_game_data table yet. Copying datasets does not copy views so we will always need to run this step even if you copied the entire dataset directly.\n",
    "\n",
    "**IMPORTANT** If you ever change the number of games to use for the weighted moving average (W) then you will need to update this view as well. The game_number < filter needs to change to however many games you are averaging over. Future release will seek to remove this change dependency as it is too easy to miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change dataset name (nba) if you chose a different dataset name earlier\n",
    "view_name = 'nba.games_to_load_to_model'\n",
    "view_query = f'CREATE OR REPLACE VIEW `{view_name}` AS \\\n",
    "WITH model_load_games as (SELECT \\\n",
    "distinct game_key as game_key \\\n",
    "FROM `nba.model_game` \\\n",
    ") \\\n",
    "    SELECT distinct order_of_games_per_team.game_key, \\\n",
    "    CASE WHEN model_load_games.game_key is NULL THEN 1 ELSE 0 END as NEEDS_TO_LOAD_TO_MODEL \\\n",
    "    FROM ( \\\n",
    "            SELECT team, game_key, row_number() OVER (PARTITION BY team ORDER BY game_date desc) as game_number \\\n",
    "            FROM ( \\\n",
    "                    SELECT \\\n",
    "                        home_team_name as team, game_date, game_key \\\n",
    "                    FROM  `nba.raw_basketballreference_game` \\\n",
    "                    UNION DISTINCT \\\n",
    "                    SELECT \\\n",
    "                        visitor_team_name as team, game_date, game_key \\\n",
    "                    FROM  `nba.raw_basketballreference_game` \\\n",
    "                 ) games_per_team \\\n",
    "            )order_of_games_per_team \\\n",
    "    LEFT JOIN model_load_games ON model_load_games.game_key = order_of_games_per_team.game_key \\\n",
    "    WHERE team in ( \\\n",
    "                    SELECT \\\n",
    "                        distinct home_team_name as team_to_load \\\n",
    "                    FROM `nba.raw_basketballreference_game` \\\n",
    "                    WHERE \\\n",
    "                        game_key not in (SELECT game_key FROM model_load_games) \\\n",
    "                    UNION DISTINCT \\\n",
    "                    SELECT \\\n",
    "                        distinct visitor_team_name as team_to_load \\\n",
    "                    FROM `nba.raw_basketballreference_game` \\\n",
    "                    WHERE \\\n",
    "                        game_key not in (SELECT game_key FROM model_load_games))'\n",
    "\n",
    "run_view = f'''bq query --use_legacy_sql=false --project_id={new_project_id} \"{view_query}\"'''\n",
    "!{run_view}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-championship",
   "metadata": {},
   "source": [
    "## Step 10 - Create Cloud Scheduler Jobs\n",
    "\n",
    "This is only required if you wish to keep your data up to date. If you do not need to keep the data up to date, simply make sure you execute the nba_model_game_refresh and nba_get_upcoming_games functions once in order for the Web App to be able to function with most recent game and upcoming schedule information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO: Replace region with the region your cloud functions are deployed to and timezone with your desired scheduled time zone\n",
    "region = 'us-central1'\n",
    "timezone = 'America/Chicago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily scraper schedule\n",
    "uri = f'https://{region}-{new_project_id}.cloudfunctions.net/nba_basketball_reference_scraper'\n",
    "!gcloud scheduler jobs create http nba_basketball_reference_scraper_daily --project {new_project_id} \\\n",
    "--schedule \"0 6 * * *\" --uri {uri} --http-method GET \\\n",
    "--time-zone={timezone} \\\n",
    "--description=\"Calls http cloud function nba_basketball_reference_scraper every day to scrape the most recent days information and add to big query tables\"\n",
    "\n",
    "# Create daily model refresh schedule\n",
    "uri = f'https://{region}-{new_project_id}.cloudfunctions.net/nba_model_game_refresh'\n",
    "!gcloud scheduler jobs create http nba_model_game_refresh_daily --project {new_project_id} \\\n",
    "--schedule \"0 7 * * *\" --uri {uri} --http-method GET \\\n",
    "--time-zone={timezone} \\\n",
    "--description=\"Calls http cloud function nba_model_game_refresh every day to load the most recently scraped data in to the model table and most recent data for each team to firestore\"\n",
    "\n",
    "# Create upcoming games refresh schedule\n",
    "uri = f'https://{region}-{new_project_id}.cloudfunctions.net/nba_get_upcoming_games'\n",
    "!gcloud scheduler jobs create http nba_get_upcoming_games --project {new_project_id} \\\n",
    "--schedule \"0 5 * * *\" --uri {uri} --http-method GET \\\n",
    "--time-zone={timezone} \\\n",
    "--description=\"Calls http cloud function nba_get_upcoming_games every day to scrape the schedule for the upcoming week and store to cloud storage\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-porter",
   "metadata": {},
   "source": [
    "## Step 11 - Trigger Cloud Functions\n",
    "\n",
    "In order to populate Firestore with the most recent game data and cloud storage with the upcoming games the fdeploy functions must be triggered. This can be done in the Console or by using the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = '{}'\n",
    "empty_data = json.dumps(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud functions call --project {new_project_id} nba_basketball_reference_scraper --data {empty_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud functions call nba_model_game_refresh --project {new_project_id} --data {empty_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud functions call nba_get_upcoming_games --project {new_project_id} --data {empty_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-reflection",
   "metadata": {},
   "source": [
    "## Step 12 - Create Static Model Training Data View\n",
    "\n",
    "For tranparency and auditability we create a view using the model_game table for specific dates and a timestamped name. This will allow us to come back to train different models on the same data. These are created as views so they are not part of what is copied externally but you could create these as tables instead if desired but would have to pay for additional storage costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: Change timezone to your timezone if desired\n",
    "timezone = 'America/Chicago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create view that excludes first game in every seasons because rest days will be way off. \n",
    "#It will use moving average dating back to previous season.\n",
    "\n",
    "query = f\"\"\"EXECUTE IMMEDIATE CONCAT(' \\\n",
    "                CREATE OR REPLACE VIEW `nba.model_training_data_' \\\n",
    "                , FORMAT_DATE('%Y%m%d', CURRENT_DATE(\\\\\"{timezone}\\\\\")) \\\n",
    "            ,'` AS \\\n",
    "                SELECT * FROM ( \\\n",
    "                    SELECT \\\n",
    "                        *, \\\n",
    "                        ROW_NUMBER() OVER (PARTITION BY g.SEASON, g.TEAM ORDER BY g.game_date asc) as SEASON_GAME_NUMBER, \\\n",
    "                    FROM nba.model_game g \\\n",
    "            ) WHERE SEASON_GAME_NUMBER > 1 and is_home_team = 1 \\\n",
    "                and game_date < DATE_SUB(CURRENT_DATE(\\\\\"{timezone}\\\\\"), INTERVAL 1 WEEK)')\"\"\"\n",
    "\n",
    "run_query = f'''bq query --use_legacy_sql=false --project_id={new_project_id} \"{query}\"'''\n",
    "\n",
    "!{run_query}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-principal",
   "metadata": {},
   "source": [
    "## Step 13 - Create Baseline Linear Model using View\n",
    "\n",
    "We will now use the data in the view we just created to generate a linear model on all of the relevant variables. \n",
    "\n",
    "You definiltey will want to open the Console to explore the model further but that is left as a separate task.\n",
    "\n",
    "**NOTE:** This is the most time consuming and costly step. Be careful with running this too many times but definitely expirement with different modeling types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If running Step 13 on the same date as Step 12 execute this cell to set the view date\n",
    "from datetime import datetime\n",
    "view_date = datetime.now().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-pathology",
   "metadata": {},
   "source": [
    "##If running Step 13 on a different day than Step 12 change the date here to the date you created the view in Step 12  \n",
    "view_date = '20210310'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_query = f\"\"\"CREATE OR REPLACE MODEL nba.baseline_linear_model \\\n",
    "  OPTIONS(model_type='LINEAR_REG', input_label_cols=['spread']) \\\n",
    "    AS SELECT spread, \\\n",
    "        is_home_team, \\\n",
    "        incoming_is_win_streak, \\\n",
    "        incoming_is_win_streak_opponent, \\\n",
    "        incoming_wma_{W}_pace, \\\n",
    "        incoming_wma_{W}_efg_pct, \\\n",
    "        incoming_wma_{W}_tov_pct, \\\n",
    "        incoming_wma_{W}_ft_rate, \\\n",
    "        incoming_wma_{W}_off_rtg, \\\n",
    "        incoming_wma_{W}_opponent_efg_pct, \\\n",
    "        incoming_wma_{W}_opponent_tov_pct, \\\n",
    "        incoming_wma_{W}_opponent_ft_rate, \\\n",
    "        incoming_wma_{W}_opponent_off_rtg, \\\n",
    "        incoming_wma_{W}_starter_minutes_played_proportion, \\\n",
    "        incoming_wma_{W}_bench_plus_minus,\\\n",
    "        incoming_wma_{W}_opponnent_starter_minutes_played_proportion, \\\n",
    "        incoming_wma_{W}_opponent_bench_plus_minus, \\\n",
    "        incoming_rest_days - incoming_rest_days_opponent as rest_days_difference \\\n",
    "    FROM `nba.model_training_data_{view_date}`\"\"\"\n",
    "\n",
    "model_query = f'''bq query --use_legacy_sql=false --project_id={new_project_id} \"{model_query}\"'''\n",
    "\n",
    "!{model_query}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-square",
   "metadata": {},
   "source": [
    "## Step 14 Deploy App Engine App\n",
    "\n",
    "We are finally ready to deploy the app engine web app! If you have sucessfully completed all steps above then you should be able to navigate to a webpage that works the same as the [webpage](https://nba-predictions-prod.uc.r.appspot.com/) in the Readme.\n",
    "\n",
    "As a prequisite, make sure you are running this notebook in the folder from the gitclone or be sure to replace the file paths below with the correct file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud app deploy ../webapp/app.yaml --project={new_project_id} --promote --quiet\n",
    "print(f'Check you your new web page at https://{new_project_id}.uc.r.appspot.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-aberdeen",
   "metadata": {},
   "source": [
    "## Optional - Delete Project\n",
    "\n",
    "To avoid on-going charges for everything created in this workbook run the below command to delete the project that you just created. Note it will take approximately 30 days for full completion and you will stil be charged for any charges accrued during this walkthrough. Check out [Deleting GCP Project](https://cloud.google.com/resource-manager/docs/creating-managing-projects?visit_id=637510410447506984-2569255859&rd=1#shutting_down_projects) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment code to delete project\n",
    "# !gcloud projects delete {new_project_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-southwest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
